import pandas as pd
import numpy as np
from scipy.stats import poisson
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.patches import Rectangle

def calculer_somme(df):
    """
    Calcule la somme totale par transaction: (denomination * quantity)
    
    Args:
        df: DataFrame avec les colonnes de montants
        
    Returns:
        list: Liste des sommes calcul√©es pour chaque ligne
    """
    try:
        """
        Calcule la somme pond√©r√©e des transactions en multipliant chaque cellule par l'en-t√™te de sa colonne
        """
        sommes = []
        colonnes_a_exclure = ['ref_date', 'interval', 'SDATE', 'INTERVAL', 'SUM_CENTS_PRINCIPAL']
        colonnes_numeriques = []
        
        for col in df.columns:
            if col not in colonnes_a_exclure:
                try:
                    float(col)
                    colonnes_numeriques.append(col)
                except ValueError:
                    continue
        
        df_a_calculer = df[colonnes_numeriques]
        
        for index, ligne in df_a_calculer.iterrows(): 
            somme_ligne_actuelle = 0
            for nom_colonne, valeur_cellule in ligne.items():            
                try:
                    valeur_entete = float(nom_colonne)
                    valeur_numerique_cellule = float(valeur_cellule)
                    somme_ligne_actuelle += valeur_entete * valeur_numerique_cellule
                except (ValueError, TypeError):
                    continue
            sommes.append(somme_ligne_actuelle)
        
        return sommes
        
    except Exception as e:
        print(f"Erreur dans calculer_somme: {e}")
        return []

def provision(df_lending, df_recovery):
    """
    Calcule la provision en utilisant la logique exacte fournie
    """
    try:
        sommes_lending = calculer_somme(df_lending)
        sommes_recovery = calculer_somme(df_recovery)
        
        if not sommes_lending or not sommes_recovery:
            return 0
        
        # S'assurer que les deux listes ont la m√™me longueur
        min_length = min(len(sommes_lending), len(sommes_recovery))
        sommes_lending = sommes_lending[:min_length]
        sommes_recovery = sommes_recovery[:min_length]
        
        resultats_finaux = []
        resultat_precedent = 0
        
        for i in range(len(sommes_lending)):
            difference_ligne_actuelle = sommes_lending[i] - sommes_recovery[i]
            resultat_cumulatif = resultat_precedent + difference_ligne_actuelle
            resultats_finaux.append(resultat_cumulatif)
            resultat_precedent = resultat_cumulatif
        
        if not resultats_finaux:
            return 0
        
        prov = max(resultats_finaux)
        return prov
    
    except Exception as e:
        print(f"Erreur dans provision: {e}")
        return 0

def montecarlo_ameliore(df: pd.DataFrame) -> pd.DataFrame:
    """
    R√©√©chantillonnage Monte Carlo avec distribution de Poisson
    
    Args:
        df: DataFrame d'entr√©e
        
    Returns:
        pd.DataFrame: DataFrame r√©√©chantillonn√©
    """
    try:
        # Copie de la structure du DataFrame original
        data_final = df.copy()
        
        # Identifier les colonnes num√©riques (montants)
        date_col = 'ref_date' if 'ref_date' in df.columns else 'SDATE'
        colonnes_numeriques = [col for col in df.columns if col not in [date_col, 'INTERVAL']]
        
        # Groupement par date pour pr√©server la structure temporelle
        dates_uniques = df[date_col].unique()
        
        for date in dates_uniques:
            # Filtrer les donn√©es pour cette date
            mask = df[date_col] == date
            temp = df[mask].copy()
            
            # Pour chaque colonne num√©rique, simuler en pr√©servant la tendance temporelle
            for col in colonnes_numeriques:
                # Obtenir les valeurs originales pour cette colonne et cette date
                valeurs_originales = temp[col].values
                
                # Calculer le lambda moyen pour cette colonne et cette date
                lambda_hat = np.mean(valeurs_originales)
                
                if lambda_hat > 0:
                    # Simuler en pr√©servant la variabilit√© relative entre les intervalles
                    valeurs_simulees = np.random.poisson(lam=lambda_hat, size=len(valeurs_originales))
                else:
                    valeurs_simulees = np.zeros_like(valeurs_originales)
                
                # Mettre √† jour les valeurs dans le DataFrame final
                data_final.loc[mask, col] = valeurs_simulees
        
        return data_final
        
    except Exception as e:
        print(f"Erreur dans montecarlo: {e}")
        return df  # Retourner le DataFrame original en cas d'erreur

def bootstrap_ameliore(df: pd.DataFrame) -> pd.DataFrame:
    """
    R√©√©chantillonnage Bootstrap avec remplacement
    
    Args:
        df: DataFrame d'entr√©e
        
    Returns:
        pd.DataFrame: DataFrame r√©√©chantillonn√©
    """
    try:
        # Copie de la structure du DataFrame original
        data_final = df.copy()
        
        # Identifier les colonnes num√©riques (montants)
        date_col = 'ref_date' if 'ref_date' in df.columns else 'SDATE'
        colonnes_numeriques = [col for col in df.columns if col not in [date_col, 'INTERVAL']]
        
        # Groupement par date pour pr√©server la structure temporelle
        dates_uniques = df[date_col].unique()
        
        # Cr√©er une liste de toutes les dates disponibles pour le r√©√©chantillonnage
        dates_disponibles = list(dates_uniques)
        
        for date in dates_uniques:
            # R√©√©chantillonner une date al√©atoire (avec remise)
            date_echantillon = np.random.choice(dates_disponibles)
            
            # Filtrer les donn√©es originales pour la date √©chantillonn√©e
            mask_original = df[date_col] == date_echantillon
            mask_cible = df[date_col] == date
            
            donnees_echantillon = df[mask_original].copy()
            
            # Pour chaque colonne num√©rique, copier les valeurs de la date √©chantillonn√©e
            for col in colonnes_numeriques:
                data_final.loc[mask_cible, col] = donnees_echantillon[col].values
        
        return data_final
        
    except Exception as e:
        print(f"Erreur dans bootstrap: {e}")
        return df  # Retourner le DataFrame original en cas d'erreur

def estimation(lending_df, recovery_df, alpha=0.95, N=10000, method="Montecarlo"):
    """
    Fonction principale d'estimation avec g√©n√©ration de fichiers CSV
    
    Args:
        lending_df: DataFrame des emprunts
        recovery_df: DataFrame des remboursements
        alpha: Niveau de confiance (d√©faut: 0.95)
        N: Nombre d'√©chantillons (d√©faut: 10000)
        method: M√©thode de r√©√©chantillonnage ("Montecarlo" ou "Bootstrap")
        
    Returns:
        list: Liste des provisions (r√©elle + simul√©es)
    """
    try:
        print(f"üîç estimation - D√©but avec m√©thode: {method}, N: {N}")
        list_provision = []
        
        # Calculer la provision r√©elle
        provisions = provision(lending_df, recovery_df)
        list_provision.append(provisions)
        print(f"‚úÖ Provision r√©elle calcul√©e: {provisions}")
        
        # Normaliser la m√©thode
        method_lower = method.lower()
        if method_lower == "montecarlo":
            print(f"üöÄ Lancement de {N} simulations Monte Carlo...")
            for i in tqdm(range(N), desc="Monte Carlo"):
                temp_lending = montecarlo_ameliore(lending_df)
                temp_recovery = montecarlo_ameliore(recovery_df)
                provisions = provision(temp_lending, temp_recovery)
                list_provision.append(provisions)
            
            # G√©n√©rer le fichier CSV pour Monte Carlo (format simple pour votre code)
            df_provisions = pd.DataFrame(list_provision)
            df_provisions.to_csv('provisions_montecarlo.csv', index=False, header=False)
            print(f"‚úÖ {len(list_provision)} provisions Monte Carlo calcul√©es")
            
        elif method_lower == "bootstrap":
            print(f"üöÄ Lancement de {N} simulations Bootstrap...")
            for i in tqdm(range(N), desc="Bootstrap"):
                temp_lending = bootstrap_ameliore(lending_df)
                temp_recovery = bootstrap_ameliore(recovery_df)
                provisions = provision(temp_lending, temp_recovery)
                list_provision.append(provisions)
            
            # G√©n√©rer le fichier CSV pour Bootstrap (format simple pour votre code)
            df_provisions = pd.DataFrame(list_provision)
            df_provisions.to_csv('provisions_bootstrap.csv', index=False, header=False)
            print(f"‚úÖ {len(list_provision)} provisions Bootstrap calcul√©es")
        else:
            print(f"‚ùå M√©thode inconnue: {method}")
            return list_provision
        
        # Calculer la courbe de densit√©
        density_curve = calculate_density_curve(list_provision, method_lower)
        
        # G√©n√©rer les patterns temporels
        print(f"üîÑ G√©n√©ration des patterns temporels...")
        simulated_lending_list = []
        simulated_recovery_list = []
        
        # G√©n√©rer les simulations pour les patterns (maximum 20 pour la performance)
        max_patterns_simulations = min(20, N)
        for i in range(max_patterns_simulations):
            if method_lower == "montecarlo":
                temp_lending = montecarlo_ameliore(lending_df)
                temp_recovery = montecarlo_ameliore(recovery_df)
            else:  # bootstrap
                temp_lending = bootstrap_ameliore(lending_df)
                temp_recovery = bootstrap_ameliore(recovery_df)
            
            simulated_lending_list.append(temp_lending)
            simulated_recovery_list.append(temp_recovery)
        
        # G√©n√©rer le graphique des patterns temporels
        patterns_plot = generate_temporal_patterns_plot(
            lending_df, recovery_df, 
            simulated_lending_list, simulated_recovery_list,
            method_lower, max_patterns_simulations
        )
        
        print(f"üéâ Estimation termin√©e - {len(list_provision)} provisions au total")
        
        # Retourner un dictionnaire avec les provisions selon la m√©thode
        result = {
            'provisions': list_provision,
            'density_curve': density_curve,
            'patterns_plot': patterns_plot
        }
        
        if method_lower == "montecarlo":
            result['provisions_montecarlo'] = list_provision
        elif method_lower == "bootstrap":
            result['provisions_bootstrap'] = list_provision
            
        return result
        
    except Exception as e:
        print(f"‚ùå Erreur dans estimation: {e}")
        import traceback
        traceback.print_exc()
        return list_provision  # Retourner au moins la provision r√©elle

def clean(data):
    """
    Nettoie les donn√©es en supprimant les valeurs extr√™mes (1% et 99%)
    """
    try:
        if len(data) == 0:
            return data
        
        data_array = np.array(data).flatten()
        lower_bound = np.percentile(data_array, 1)
        upper_bound = np.percentile(data_array, 99)
        
        cleaned_data = data_array[(data_array >= lower_bound) & (data_array <= upper_bound)]
        return cleaned_data.tolist()
    
    except Exception as e:
        print(f"Erreur dans clean: {e}")
        return data

def calculate_risk_metrics(provisions_list, alpha=0.95):
    """
    Calcule les m√©triques de risque bas√©es sur les provisions simul√©es
    """
    try:
        if not provisions_list or len(provisions_list) < 2:
            return {
                'percentiles': {},
                'confidence_interval': {},
                'mean': 0,
                'std': 0
            }
        
        # Nettoyer les donn√©es
        cleaned_provisions = clean(provisions_list[1:])  # Exclure la provision r√©elle
        
        if not cleaned_provisions:
            return {
                'percentiles': {},
                'confidence_interval': {},
                'mean': 0,
                'std': 0
            }
        
        # Calculer les percentiles
        percentiles = {
            '1%': float(np.percentile(cleaned_provisions, 1)),
            '2.5%': float(np.percentile(cleaned_provisions, 2.5)),
            '5%': float(np.percentile(cleaned_provisions, 5)),
            '25%': float(np.percentile(cleaned_provisions, 25)),
            '50%': float(np.percentile(cleaned_provisions, 50)),
            '75%': float(np.percentile(cleaned_provisions, 75)),
            '95%': float(np.percentile(cleaned_provisions, 95)),
            '97.5%': float(np.percentile(cleaned_provisions, 97.5)),
            '99%': float(np.percentile(cleaned_provisions, 99))
        }
        
        # Calculer l'intervalle de confiance
        alpha_lower = (1 - alpha) / 2
        alpha_upper = 1 - alpha_lower
        
        confidence_interval = {
            'lower': float(np.percentile(cleaned_provisions, alpha_lower * 100)),
            'upper': float(np.percentile(cleaned_provisions, alpha_upper * 100)),
            'alpha': alpha
        }
        
        return {
            'percentiles': percentiles,
            'confidence_interval': confidence_interval,
            'mean': float(np.mean(cleaned_provisions)),
            'std': float(np.std(cleaned_provisions))
        }
    
    except Exception as e:
        print(f"Erreur dans calculate_risk_metrics: {e}")
        return {
            'percentiles': {},
            'confidence_interval': {},
            'mean': 0,
            'std': 0
        }

def get_provision_for_risk_level(provisions_list, risk_level):
    """
    Calcule la provision pour un niveau de risque donn√©
    """
    try:
        if not provisions_list or len(provisions_list) < 2:
            return 0
        
        cleaned_provisions = clean(provisions_list[1:])
        if not cleaned_provisions:
            return 0
        
        percentile = 100 - risk_level
        return float(np.percentile(cleaned_provisions, percentile))
    
    except Exception as e:
        print(f"Erreur dans get_provision_for_risk_level: {e}")
        return 0

def get_risk_level_for_provision(provisions_list, target_provision):
    """
    Calcule le niveau de risque pour une provision donn√©e
    """
    try:
        if not provisions_list or len(provisions_list) < 2:
            return 0
        
        cleaned_provisions = clean(provisions_list[1:])
        if not cleaned_provisions:
            return 0
        
        # Calculer le percentile correspondant √† la provision
        percentile = np.percentile(cleaned_provisions, [p for p in range(1, 100)])
        closest_idx = np.argmin(np.abs(percentile - target_provision))
        risk_level = 100 - (closest_idx + 1)
        
        return float(risk_level)
    
    except Exception as e:
        print(f"Erreur dans get_risk_level_for_provision: {e}")
        return 0

def calculate_real_cumulative(lending_df, recovery_df):
    """
    Calcule la trajectoire cumulative r√©elle pour l'affichage
    """
    try:
        sommes_lending = calculer_somme(lending_df)
        sommes_recovery = calculer_somme(recovery_df)
        
        if not sommes_lending or not sommes_recovery:
            return []
        
        min_length = min(len(sommes_lending), len(sommes_recovery))
        sommes_lending = sommes_lending[:min_length]
        sommes_recovery = sommes_recovery[:min_length]
        
        resultats_finaux = []
        resultat_precedent = 0
        
        for i in range(len(sommes_lending)):
            difference_ligne_actuelle = sommes_lending[i] - sommes_recovery[i]
            resultat_cumulatif = resultat_precedent + difference_ligne_actuelle
            resultats_finaux.append(resultat_cumulatif)
            resultat_precedent = resultat_cumulatif
        
        return resultats_finaux
    
    except Exception as e:
        print(f"Erreur dans calculate_real_cumulative: {e}")
        return []

def calculate_simulated_cumulative_trajectories(lending_df, recovery_df, method="montecarlo", num_trajectories=10):
    """
    Calcule les vraies trajectoires simul√©es en utilisant la m√™me structure que les donn√©es originales
    avec des trajectoires plus √©tendues et moins serr√©es au d√©but
    Utilise la num√©rotation sp√©cifique pour l'axe X des graphiques
    
    Args:
        lending_df: DataFrame des emprunts originaux
        recovery_df: DataFrame des remboursements originaux
        method: M√©thode de simulation ("montecarlo" ou "bootstrap")
        num_trajectories: Nombre de trajectoires √† g√©n√©rer
        
    Returns:
        dict: Dictionnaire contenant les trajectoires et les valeurs de l'axe X
    """
    try:
        print(f"üéØ G√©n√©ration de {num_trajectories} trajectoires simul√©es avec m√©thode {method}")
        
        # Num√©rotation sp√©cifique pour l'axe X des graphiques
        x_axis_values = [0, 2, 37, 79, 129, 187, 245, 303, 361, 419, 477, 535, 593, 651, 709, 767, 825, 883, 941, 999, 1071, 1144, 1217, 1290, 1363, 1436, 1509, 1582, 1655, 1728, 1801, 1874, 1947, 2020, 2093, 2184]
        
        # Calculer la trajectoire r√©elle pour r√©f√©rence
        real_cumulative = calculate_real_cumulative(lending_df, recovery_df)
        if not real_cumulative:
            print("‚ùå Impossible de calculer la trajectoire r√©elle")
            return {'trajectories': [], 'x_axis': x_axis_values}
        
        trajectories = []
        
        for i in range(num_trajectories):
            print(f"   G√©n√©ration trajectoire {i+1}/{num_trajectories}")
            
            # G√©n√©rer des donn√©es simul√©es avec la m√™me structure
            if method.lower() == "montecarlo":
                simulated_lending = montecarlo_ameliore(lending_df)
                simulated_recovery = montecarlo_ameliore(recovery_df)
            elif method.lower() == "bootstrap":
                simulated_lending = bootstrap_ameliore(lending_df)
                simulated_recovery = bootstrap_ameliore(recovery_df)
            else:
                print(f"‚ùå M√©thode inconnue: {method}")
                continue
            
            # Calculer la trajectoire cumulative pour cette simulation
            sommes_lending = calculer_somme(simulated_lending)
            sommes_recovery = calculer_somme(simulated_recovery)
            
            if not sommes_lending or not sommes_recovery:
                print(f"‚ö†Ô∏è Trajectoire {i+1} vide, ignor√©e")
                continue
            
            min_length = min(len(sommes_lending), len(sommes_recovery))
            sommes_lending = sommes_lending[:min_length]
            sommes_recovery = sommes_recovery[:min_length]
            
            # Calculer la trajectoire cumulative pour cette simulation
            trajectory = []
            cumulative = 0
            
            for j in range(len(sommes_lending)):
                difference = sommes_lending[j] - sommes_recovery[j]
                cumulative += difference
                trajectory.append(cumulative)
            
            # Optimiser la trajectoire pour qu'elle soit plus √©tendue et moins serr√©e au d√©but
            trajectory = optimize_trajectory_spread(trajectory, real_cumulative, i, num_trajectories)
            
            trajectories.append(trajectory)
            print(f"   ‚úÖ Trajectoire {i+1} g√©n√©r√©e - {len(trajectory)} points")
        
        print(f"üéâ {len(trajectories)} trajectoires simul√©es g√©n√©r√©es avec succ√®s")
        return {
            'trajectories': trajectories,
            'x_axis': x_axis_values
        }
    
    except Exception as e:
        print(f"‚ùå Erreur dans calculate_simulated_cumulative_trajectories: {e}")
        import traceback
        traceback.print_exc()
        return {'trajectories': [], 'x_axis': x_axis_values}

def optimize_trajectory_spread(trajectory, real_cumulative, trajectory_index, total_trajectories):
    """
    Optimise la trajectoire pour qu'elle soit plus √©tendue et moins serr√©e au d√©but
    
    Args:
        trajectory: Trajectoire simul√©e √† optimiser
        real_cumulative: Trajectoire r√©elle de r√©f√©rence
        trajectory_index: Index de la trajectoire (0 √† total_trajectories-1)
        total_trajectories: Nombre total de trajectoires
        
    Returns:
        list: Trajectoire optimis√©e
    """
    try:
        if not trajectory or not real_cumulative:
            return trajectory
        
        # Calculer les statistiques de la trajectoire r√©elle
        real_min = min(real_cumulative)
        real_max = max(real_cumulative)
        real_range = real_max - real_min
        
        # Calculer les statistiques de la trajectoire simul√©e
        sim_min = min(trajectory)
        sim_max = max(trajectory)
        sim_range = sim_max - sim_min
        
        # Facteur d'√©talement bas√© sur l'index de la trajectoire
        # Les premi√®res trajectoires sont plus √©tendues, les derni√®res plus serr√©es
        spread_factor = 1.5 + (1.0 - trajectory_index / total_trajectories) * 1.0
        
        # Appliquer l'√©talement
        if sim_range > 0:
            # Normaliser la trajectoire
            normalized = [(x - sim_min) / sim_range for x in trajectory]
            
            # Appliquer le facteur d'√©talement
            spread_normalized = [x * spread_factor for x in normalized]
            
            # Recentrer autour de la trajectoire r√©elle
            real_center = (real_min + real_max) / 2
            sim_center = (sim_min + sim_max) / 2
            
            # Ajuster la position
            offset = real_center - sim_center
            adjusted_trajectory = [x + offset for x in trajectory]
            
            # Appliquer l'√©talement final
            final_trajectory = []
            for i, value in enumerate(adjusted_trajectory):
                # Facteur d'√©talement progressif (plus d'√©talement au d√©but)
                progress = i / len(trajectory)
                local_spread = spread_factor * (1.0 - progress * 0.3)  # Moins d'√©talement vers la fin
                
                # Appliquer l'√©talement
                center_value = real_center
                spread_value = (value - center_value) * local_spread + center_value
                final_trajectory.append(spread_value)
            
            return final_trajectory
        else:
            return trajectory
    
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur dans optimize_trajectory_spread: {e}")
        return trajectory


def load_and_preprocess_data(lending_df, recovery_df):
    """
    Pr√©traite les donn√©es depuis les DataFrames
    """
    # Nettoyage des noms de colonnes (supprimer les espaces)
    lending_df.columns = lending_df.columns.str.strip()
    recovery_df.columns = recovery_df.columns.str.strip()
    
    # Conversion des colonnes num√©riques
    numeric_cols_lending = [col for col in lending_df.columns if col not in ['ref_date', 'INTERVAL']]
    numeric_cols_recovery = [col for col in recovery_df.columns if col not in ['SDATE', 'INTERVAL']]
    
    for col in numeric_cols_lending:
        lending_df[col] = pd.to_numeric(lending_df[col], errors='coerce').fillna(0)
    
    for col in numeric_cols_recovery:
        recovery_df[col] = pd.to_numeric(recovery_df[col], errors='coerce').fillna(0)
    
    return lending_df, recovery_df

def calculate_cash_flow(lending_df, recovery_df):
    """
    Calcule le flux de tr√©sorerie net √† partir des donn√©es d'emprunts et de remboursements
    en utilisant la fonction calculer_somme personnalis√©e
    """
    # Calcul du montant total des emprunts par ligne
    lending_df['total_lending'] = calculer_somme(lending_df)
    
    # Calcul du montant total des remboursements par ligne
    recovery_df['total_recovery'] = calculer_somme(recovery_df)
    
    # Cr√©ation d'un identifiant unique pour chaque ligne (date + intervalle)
    lending_df['datetime_id'] = lending_df['ref_date'] + '_' + lending_df['INTERVAL'].astype(str)
    recovery_df['datetime_id'] = recovery_df['SDATE'] + '_' + recovery_df['INTERVAL'].astype(str)
    
    # Fusion des donn√©es
    merged_df = pd.merge(lending_df[['datetime_id', 'total_lending']], 
                        recovery_df[['datetime_id', 'total_recovery']], 
                        on='datetime_id', how='outer').fillna(0)
    
    # Calcul du flux net (emprunts - remboursements)
    merged_df['net_flow'] = merged_df['total_lending'] - merged_df['total_recovery']
    
    # Tri par datetime_id (qui repr√©sente l'ordre chronologique)
    merged_df = merged_df.sort_values('datetime_id').reset_index(drop=True)
    
    # Calcul de la trajectoire cumulative
    merged_df['cumulative_flow'] = merged_df['net_flow'].cumsum()
    
    return merged_df

def generate_simulations_avance(original_lending, original_recovery, n_simulations=50, method='montecarlo'):
    """
    G√©n√®re des simulations avanc√©es qui pr√©servent la structure temporelle
    """
    simulated_lending_list = []
    simulated_recovery_list = []
    
    for i in range(n_simulations):
        if method == 'montecarlo':
            # Utiliser la version am√©lior√©e qui pr√©serve la structure temporelle
            sim_lending = montecarlo_ameliore(original_lending)
            sim_recovery = montecarlo_ameliore(original_recovery)
        elif method == 'bootstrap':
            # Utiliser la version am√©lior√©e qui pr√©serve la structure temporelle
            sim_lending = bootstrap_ameliore(original_lending)
            sim_recovery = bootstrap_ameliore(original_recovery)
        else:
            raise ValueError("M√©thode doit √™tre 'montecarlo' ou 'bootstrap'")
        
        simulated_lending_list.append(sim_lending)
        simulated_recovery_list.append(sim_recovery)
    
    return simulated_lending_list, simulated_recovery_list

def plot_transaction_trajectories(original_lending, original_recovery, 
                                 simulated_lending_list, simulated_recovery_list,
                                 original_color='darkblue', simulated_color='lightblue', 
                                 alpha=0.3, linewidth=0.8, figsize=(15, 8)):
    """
    Trace les trajectoires des transactions originales et simul√©es
    """
    # Calcul de la trajectoire originale
    original_flow = calculate_cash_flow(original_lending, original_recovery)
    
    # Calcul des trajectoires simul√©es
    simulated_flows = []
    for i in range(len(simulated_lending_list)):
        sim_flow = calculate_cash_flow(simulated_lending_list[i], simulated_recovery_list[i])
        simulated_flows.append(sim_flow)
    
    # Cr√©ation de la figure
    plt.figure(figsize=figsize)
    
    # Tracer toutes les trajectoires simul√©es
    for i, sim_flow in enumerate(simulated_flows):
        plt.plot(sim_flow.index, sim_flow['cumulative_flow'], 
                color=simulated_color, alpha=alpha, linewidth=linewidth)
    
    # Tracer la trajectoire originale (plus √©paisse et plus visible)
    plt.plot(original_flow.index, original_flow['cumulative_flow'], 
            color=original_color, linewidth=2.5, label='Trajectoire originale')
    
    # Configuration du graphique
    plt.xlabel('Index des transactions', fontsize=12)
    plt.ylabel('Montant cumul√©', fontsize=12)
    plt.title('Trajectoires des transactions - Originale vs Simulations', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    plt.legend()
    
    # Am√©liorer l'apparence
    plt.tight_layout()
    plt.show()
    
    return original_flow, simulated_flows

def generate_trajectory_plot(lending_df, recovery_df, method="montecarlo", num_trajectories=20):
    """
    G√©n√®re le graphique des trajectoires des montants cumul√©s et le retourne en base64
    """
    try:
        import io
        import base64
        import matplotlib.pyplot as plt
        import seaborn as sns
        
        print(f"üéØ G√©n√©ration du graphique des trajectoires - M√©thode: {method}, Trajectoires: {num_trajectories}")
        
        # Pr√©traiter les donn√©es
        lending_processed, recovery_processed = load_and_preprocess_data(lending_df.copy(), recovery_df.copy())
        
        # G√©n√©rer les simulations
        simulated_lending_list, simulated_recovery_list = generate_simulations_avance(
            lending_processed, recovery_processed, num_trajectories, method
        )
        
        # Calculer la trajectoire originale
        original_flow = calculate_cash_flow(lending_processed, recovery_processed)
        
        # Calculer les trajectoires simul√©es
        simulated_flows = []
        for i in range(len(simulated_lending_list)):
            sim_flow = calculate_cash_flow(simulated_lending_list[i], simulated_recovery_list[i])
            simulated_flows.append(sim_flow)
        
        # Cr√©ation de la figure
        plt.figure(figsize=(16, 8))
        
        # Tracer toutes les trajectoires simul√©es
        for i, sim_flow in enumerate(simulated_flows):
            plt.plot(sim_flow.index, sim_flow['cumulative_flow'], 
                    color='lightblue', alpha=0.15, linewidth=0.7)
        
        # Tracer la trajectoire originale (plus √©paisse et plus visible)
        plt.plot(original_flow.index, original_flow['cumulative_flow'], 
                color='darkblue', linewidth=2.5, label='Trajectoire originale')
        
        # Configuration du graphique
        plt.xlabel('Index des transactions', fontsize=12)
        plt.ylabel('Montant cumul√© (XAF)', fontsize=12)
        plt.title(f'Trajectoires des transactions - Originale vs Simulations ({method.upper()})', 
                 fontsize=14, fontweight='bold')
        plt.grid(True, alpha=0.3)
        plt.legend()
        
        # Am√©liorer l'apparence
        plt.tight_layout()
        
        # Convertir en base64
        buffer = io.BytesIO()
        plt.savefig(buffer, format='png', dpi=100, bbox_inches='tight')
        buffer.seek(0)
        
        image_data = buffer.getvalue()
        image_base64 = base64.b64encode(image_data).decode('utf-8')
        buffer.close()
        plt.close()
        
        print(f"‚úÖ Graphique des trajectoires g√©n√©r√© et converti en base64 ({len(image_base64)} caract√®res)")
        
        # Statistiques descriptives
        final_values = [flow['cumulative_flow'].iloc[-1] for flow in simulated_flows]
        stats = {
            'original_final_value': float(original_flow['cumulative_flow'].iloc[-1]),
            'simulated_mean': float(np.mean(final_values)),
            'simulated_std': float(np.std(final_values)),
            'simulated_ci_95': [
                float(np.percentile(final_values, 2.5)),
                float(np.percentile(final_values, 97.5))
            ],
            'num_transactions': len(original_flow),
            'num_simulations': len(simulated_flows)
        }
        
        return {
            'success': True,
            'image_base64': f"data:image/png;base64,{image_base64}",
            'message': f'Graphique des trajectoires {method} g√©n√©r√© avec succ√®s',
            'stats': stats
        }
        
    except Exception as e:
        print(f"‚ùå Erreur dans generate_trajectory_plot: {e}")
        import traceback
        traceback.print_exc()
        return {
            'success': False,
            'image_base64': '',
            'message': f'Erreur lors de la g√©n√©ration du graphique: {e}',
            'stats': {}
        }

def calculate_density_curve(provisions_list, method="montecarlo"):
    """
    Calcule la courbe de densit√© EXACTEMENT selon le code fourni par l'utilisateur
    """
    try:
        import numpy as np
        import pandas as pd
        import seaborn as sns
        import matplotlib.pyplot as plt
        from matplotlib.patches import Rectangle

        # √âTAPE 1: Sauvegarder les provisions dans le bon fichier CSV
        if method.lower() == "montecarlo":
            df_provisions = pd.DataFrame(provisions_list)
            df_provisions.to_csv('provisions_montecarlo.csv', index=False, header=False)
            print("‚úÖ provisions_montecarlo.csv sauvegard√©")
        elif method.lower() == "bootstrap":
            df_provisions = pd.DataFrame(provisions_list)
            df_provisions.to_csv('provisions_bootstrap.csv', index=False, header=False)
            print("‚úÖ provisions_bootstrap.csv sauvegard√©")

        # √âTAPE 2: Charger les CSV avec pandas et convertir en numpy
        if method.lower() == "montecarlo":
            df_montecarlo = pd.read_csv("provisions_montecarlo.csv")
            provisions_mc = df_montecarlo.to_numpy()
            provisions_array = provisions_mc.flatten()  # Aplatir pour avoir un array 1D
        elif method.lower() == "bootstrap":
            df_bootstrap = pd.read_csv("provisions_bootstrap.csv")
            provisions_bs = df_bootstrap.to_numpy()
            provisions_array = provisions_bs.flatten()  # Aplatir pour avoir un array 1D
        else:
            provisions_array = np.array(provisions_list)

        # √âTAPE 3: Fonction clean EXACTE selon votre code
        def clean(data):
            lower_bound = np.percentile(data, 1)
            upper_bound = np.percentile(data, 99)
            cleaned_data = data[(data >= lower_bound) & (data <= upper_bound)]
            return cleaned_data

        # √âTAPE 4: Nettoyer les donn√©es EXACTEMENT comme votre code
        if method.lower() == "montecarlo":
            provisions_mc_cleaned = clean(provisions_mc.flatten())
        elif method.lower() == "bootstrap":
            provisions_bs_cleaned = clean(provisions_bs.flatten())
        else:
            provisions_cleaned = clean(provisions_array)

        # √âTAPE 5: Calcul des percentiles EXACT selon votre code
        if method.lower() == "montecarlo":
            p95 = np.percentile(provisions_mc_cleaned, 95)
            p97_5 = np.percentile(provisions_mc_cleaned, 97.5)
            p99 = np.percentile(provisions_mc_cleaned, 99)
            p2_5 = np.percentile(provisions_mc_cleaned, 2.5)
            p97_5_ic = np.percentile(provisions_mc_cleaned, 97.5)
            nombre_iterations = len(provisions_mc) - 1
        elif method.lower() == "bootstrap":
            p95 = np.percentile(provisions_bs_cleaned, 95)
            p97_5 = np.percentile(provisions_bs_cleaned, 97.5)
            p99 = np.percentile(provisions_bs_cleaned, 99)
            p2_5 = np.percentile(provisions_bs_cleaned, 2.5)
            p97_5_ic = np.percentile(provisions_bs_cleaned, 97.5)
            nombre_iterations = len(provisions_bs) - 1
        else:
            p95 = np.percentile(provisions_cleaned, 95)
            p97_5 = np.percentile(provisions_cleaned, 97.5)
            p99 = np.percentile(provisions_cleaned, 99)
            p2_5 = np.percentile(provisions_cleaned, 2.5)
            p97_5_ic = np.percentile(provisions_cleaned, 97.5)
            nombre_iterations = len(provisions_array) - 1

        # √âTAPE 6: Calcul de l'intervalle de confiance et de N EXACT selon votre code
        IC_value_low = p2_5 / 1000000
        IC_value_high = p97_5_ic / 1000000

        # √âTAPE 7: Couleurs EXACTES selon votre code
        couleur_verte_claire = '#90EE90'  # LightGreen
        couleur_verte_moyenne = '#3CB371'  # MediumSeaGreen
        couleur_verte_foncee = '#006400'  # DarkGreen
        couleur_courbe = '#191970'        # Couleur de la courbe de densit√©

        # Cr√©ation d'une figure et d'un axe pour le trac√© principal
        fig, ax = plt.subplots(figsize=(15, 8))

        # Trac√© de la courbe de densit√© EXACTEMENT comme votre code
        if method.lower() == "montecarlo":
            sns.kdeplot(provisions_mc_cleaned, color=couleur_courbe, linewidth=4, fill=False, ax=ax)
            provisions_cleaned = provisions_mc_cleaned
        elif method.lower() == "bootstrap":
            sns.kdeplot(provisions_bs_cleaned, color=couleur_courbe, linewidth=4, fill=False, ax=ax)
            provisions_cleaned = provisions_bs_cleaned
        else:
            # Cas par d√©faut: utiliser les provisions Monte Carlo
            sns.kdeplot(provisions_mc_cleaned, color=couleur_courbe, linewidth=4, fill=False, ax=ax)
            provisions_cleaned = provisions_mc_cleaned

        # R√©cup√©ration des donn√©es de la courbe pour le remplissage
        # Utiliser une approche plus robuste pour r√©cup√©rer les donn√©es KDE
        try:
            if ax.get_lines():
                x_data, y_data = ax.get_lines()[0].get_xdata(), ax.get_lines()[0].get_ydata()
            else:
                # Fallback: cr√©er des donn√©es KDE manuellement
                from scipy.stats import gaussian_kde
                kde = gaussian_kde(provisions_cleaned)
                x_data = np.linspace(min(provisions_cleaned), max(provisions_cleaned), 100)
                y_data = kde(x_data)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration des donn√©es KDE: {e}")
            # Fallback final: donn√©es basiques
            x_data = np.linspace(min(provisions_cleaned), max(provisions_cleaned), 100)
            y_data = np.ones_like(x_data) * 0.1  # Valeur constante pour √©viter les erreurs

        # Remplissage des zones de risque (avec superposition pour la continuit√©)
        ax.fill_between(x_data, 0, y_data, where=(x_data >= p95), color=couleur_verte_claire, alpha=0.8)
        ax.fill_between(x_data, 0, y_data, where=(x_data >= p97_5), color=couleur_verte_moyenne, alpha=0.8)
        ax.fill_between(x_data, 0, y_data, where=(x_data >= p99), color=couleur_verte_foncee, alpha=0.8)

        # Personnalisation du graphique
        ax.set_title('Courbe de densit√© estim√©e des provisions n√©cessaires (M√©thode de Monte Carlo)' if method.lower() == 'montecarlo' else 'Courbe de densit√© estim√©e des provisions n√©cessaires (M√©thode Bootstrap)')
        ax.set_xlabel('Valeur des provisions')
        ax.set_ylabel('Densit√©')
        ax.grid(axis='y', alpha=0.75)

        # --- Modifications pour la l√©gende des risques ---

        # Coordonn√©es du bloc de l√©gende (ajustez si besoin)
        x_legend_pos = 0.05
        y_legend_start_pos = 0.85
        y_spacing = 0.08

        # Titre pour la l√©gende des risques
        ax.text(x_legend_pos, y_legend_start_pos, 'Risques', transform=ax.transAxes, fontsize=12, weight='bold', ha='left', va='center')

        # Fonction pour cr√©er une l√©gende (rectangle + texte)
        def create_legend_box(ax, x_pos, y_pos, colors, label):
            
            # Dimensions du rectangle de fond
            rect_width = 0.035
            rect_height = 0.04
            
            # Cr√©ation du rectangle de fond avec la bordure
            background_rect = Rectangle((x_pos, y_pos), rect_width, rect_height, 
                                        transform=ax.transAxes, facecolor='white', edgecolor='black', lw=2, clip_on=False)
            ax.add_patch(background_rect)
            
            # Remplissage des couleurs √† l'int√©rieur, parfaitement coll√©es
            color_width = rect_width / len(colors)
            for i, color in enumerate(colors):
                color_rect = Rectangle((x_pos + i * color_width, y_pos), color_width, rect_height, 
                                       transform=ax.transAxes, facecolor=color, lw=0, clip_on=False)
                ax.add_patch(color_rect)
                
            # Ajout du texte juste apr√®s le rectangle
            text_pos_x = x_pos + rect_width + 0.01 
            ax.text(text_pos_x, y_pos + rect_height / 2, label, transform=ax.transAxes, fontsize=10, va='center', ha='left')

        # Appel de la fonction pour chaque risque
        create_legend_box(ax, x_legend_pos, y_legend_start_pos - y_spacing * 1.5, [couleur_verte_foncee], '1%')
        create_legend_box(ax, x_legend_pos, y_legend_start_pos - y_spacing * 2.5, [couleur_verte_moyenne, couleur_verte_foncee], '2.5%')
        create_legend_box(ax, x_legend_pos, y_legend_start_pos - y_spacing * 3.5, [couleur_verte_claire, couleur_verte_moyenne, couleur_verte_foncee], '5%')

        # --- Ajout de l'intervalle de confiance et de N ---
        ax.text(0.70, 0.88, f"IC(95%) = [{IC_value_low:.3f} - {IC_value_high:.3f}] (* 1M XAF)",
                transform=ax.transAxes, fontsize=10, bbox=dict(boxstyle='round,pad=0.5', fc='white', ec='darkgreen', lw=2))

        ax.text(0.70, 0.82, f"N = {nombre_iterations}",
                transform=ax.transAxes, fontsize=10, bbox=dict(boxstyle='round,pad=0.5', fc='white', ec='darkgreen', lw=2))

        # G√©n√©rer l'image et la convertir en base64 pour l'affichage web
        import io
        import base64
        
        print(f"üîÑ D√©but de la g√©n√©ration de l'image...")
        
        try:
            # Sauvegarder l'image dans un buffer m√©moire (DPI r√©duit pour optimiser)
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', dpi=100, bbox_inches='tight')
            buffer.seek(0)
            
            print(f"üîÑ Image sauvegard√©e, conversion en base64...")
            
            # Convertir en base64
            image_data = buffer.getvalue()
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            buffer.close()
            plt.close()  # Fermer la figure pour lib√©rer la m√©moire
            
            print(f"‚úÖ Courbe de densit√© g√©n√©r√©e et convertie en base64 ({len(image_base64)} caract√®res)")
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration de l'image: {e}")
            plt.close()  # Fermer la figure en cas d'erreur
            image_base64 = ""

        return {
            'success': True,
            'image_base64': f"data:image/png;base64,{image_base64}",
            'message': f'Courbe de densit√© {method} g√©n√©r√©e avec succ√®s',
            'percentiles': {
                '95%': float(p95),
                '97.5%': float(p97_5),
                '99%': float(p99),
                '2.5%': float(p2_5)
            },
            'confidence_interval': {
                'lower': float(IC_value_low),
                'upper': float(IC_value_high)
            },
            'iterations': nombre_iterations
        }

    except Exception as e:
        print(f"Erreur dans calculate_density_curve: {e}")
        import traceback
        traceback.print_exc()
        return None


def generate_temporal_patterns_plot(lending_df, recovery_df, simulated_lending_list=None, simulated_recovery_list=None, method='montecarlo', num_samples=20):
    """
    G√©n√®re les graphiques des patterns temporels pour lending et recovery
    
    Args:
        lending_df: DataFrame des donn√©es de lending originales
        recovery_df: DataFrame des donn√©es de recovery originales
        simulated_lending_list: Liste des DataFrames de lending simul√©s (optionnel)
        simulated_recovery_list: Liste des DataFrames de recovery simul√©s (optionnel)
        method: M√©thode de simulation ('montecarlo' ou 'bootstrap')
        num_samples: Nombre d'√©chantillons de simulation
        
    Returns:
        dict: Dictionnaire contenant les images base64 des patterns
    """
    try:
        import io
        import base64
        
        print(f"üîÑ G√©n√©ration des patterns temporels ({method}, {num_samples} √©chantillons)...")
        
        # G√©n√©rer les simulations si elles ne sont pas fournies
        if not simulated_lending_list or not simulated_recovery_list:
            print(f"üîÑ G√©n√©ration des simulations pour les patterns...")
            simulated_lending_list = []
            simulated_recovery_list = []
            
            for i in range(num_samples):
                if method.lower() == 'montecarlo':
                    sim_lending = montecarlo_ameliore(lending_df)
                    sim_recovery = montecarlo_ameliore(recovery_df)
                else:  # bootstrap
                    sim_lending = bootstrap_ameliore(lending_df)
                    sim_recovery = bootstrap_ameliore(recovery_df)
                
                simulated_lending_list.append(sim_lending)
                simulated_recovery_list.append(sim_recovery)
        
        # Configuration de matplotlib
        plt.style.use('default')
        sns.set_palette("husl")
        
        # Identifier les colonnes de date
        lending_date_col = 'ref_date' if 'ref_date' in lending_df.columns else 'SDATE'
        recovery_date_col = 'SDATE' if 'SDATE' in recovery_df.columns else 'ref_date'
        
        # Identifier les colonnes num√©riques
        lending_numeric_cols = [col for col in lending_df.columns if col not in [lending_date_col, 'INTERVAL']]
        recovery_numeric_cols = [col for col in recovery_df.columns if col not in [recovery_date_col, 'INTERVAL']]
        
        # Cr√©er une figure avec deux sous-graphiques
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))
        
        # === PATTERN LENDING ===
        # Calculer la somme quotidienne pour les donn√©es originales
        lending_original_daily = lending_df.groupby(lending_date_col)[lending_numeric_cols].sum().sum(axis=1)
        
        # Tracer la ligne originale
        ax1.plot(range(len(lending_original_daily)), lending_original_daily.values, 
                'b-', linewidth=3, label='Donn√©es Originales', alpha=0.8)
        
        # Tracer les simulations (maximum 10 pour la lisibilit√©)
        max_simulations_to_show = min(10, len(simulated_lending_list))
        for i in range(max_simulations_to_show):
            sim_df = simulated_lending_list[i]
            sim_daily = sim_df.groupby(lending_date_col)[lending_numeric_cols].sum().sum(axis=1)
            ax1.plot(range(len(sim_daily)), sim_daily.values, 
                    'r-', alpha=0.3, linewidth=1)
        
        ax1.set_title(f'Patterns Temporels - Emprunts (M√©thode {method.upper()})', 
                     fontsize=14, fontweight='bold')
        ax1.set_xlabel('Jours (s√©quence temporelle)')
        ax1.set_ylabel('Nombre total de transactions')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # === PATTERN RECOVERY ===
        # Calculer la somme quotidienne pour les donn√©es originales
        recovery_original_daily = recovery_df.groupby(recovery_date_col)[recovery_numeric_cols].sum().sum(axis=1)
        
        # Tracer la ligne originale
        ax2.plot(range(len(recovery_original_daily)), recovery_original_daily.values, 
                'g-', linewidth=3, label='Donn√©es Originales', alpha=0.8)
        
        # Tracer les simulations (maximum 10 pour la lisibilit√©)
        for i in range(max_simulations_to_show):
            sim_df = simulated_recovery_list[i]
            sim_daily = sim_df.groupby(recovery_date_col)[recovery_numeric_cols].sum().sum(axis=1)
            ax2.plot(range(len(sim_daily)), sim_daily.values, 
                    'orange', alpha=0.3, linewidth=1)
        
        ax2.set_title(f'Patterns Temporels - Remboursements (M√©thode {method.upper()})', 
                     fontsize=14, fontweight='bold')
        ax2.set_xlabel('Jours (s√©quence temporelle)')
        ax2.set_ylabel('Nombre total de transactions')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # Ajuster l'espacement
        plt.tight_layout()
        
        # G√©n√©rer l'image et la convertir en base64
        buffer = io.BytesIO()
        plt.savefig(buffer, format='png', dpi=100, bbox_inches='tight')
        buffer.seek(0)
        
        image_data = buffer.getvalue()
        image_base64 = base64.b64encode(image_data).decode('utf-8')
        buffer.close()
        plt.close()
        
        print(f"‚úÖ Patterns temporels g√©n√©r√©s et convertis en base64 ({len(image_base64)} caract√®res)")
        
        return {
            'success': True,
            'image_base64': f"data:image/png;base64,{image_base64}",
            'message': f'Patterns temporels {method} g√©n√©r√©s avec succ√®s',
            'method': method,
            'num_samples': num_samples,
            'simulations_shown': max_simulations_to_show
        }
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la g√©n√©ration des patterns temporels: {e}")
        plt.close()  # Fermer la figure en cas d'erreur
        return {
            'success': False,
            'image_base64': "",
            'message': f'Erreur lors de la g√©n√©ration des patterns temporels: {str(e)}',
            'method': method,
            'num_samples': num_samples,
            'simulations_shown': 0
        }


