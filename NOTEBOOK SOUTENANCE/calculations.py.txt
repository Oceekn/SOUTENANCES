calculations.py

import pandas as pd
import numpy as np
from scipy.stats import poisson
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.patches import Rectangle

def calculer_somme(df):
    """
    Calcule la somme totale par transaction: (denomination * quantity)
    
    Args:
        df: DataFrame avec les colonnes de montants
        
    Returns:
        list: Liste des sommes calcul√©es pour chaque ligne
    """
    try:
        sommes = []
        
        # Colonnes √† exclure selon les sp√©cifications exactes
        colonnes_a_exclure = ['ref_date', 'interval', 'SDATE', 'INTERVAL', 'SUM_CENTS_PRINCIPAL']
        
        # Identifier les colonnes num√©riques (montants)
        colonnes_numeriques = []
        for col in df.columns:
            if col not in colonnes_a_exclure:
                try:
                    float(col)  # V√©rifier si c'est un nombre
                    colonnes_numeriques.append(col)
                except ValueError:
                    continue  # Ignorer les colonnes non num√©riques
        
        # S√©lectionner seulement les colonnes num√©riques
        df_a_calculer = df[colonnes_numeriques]
        
        # Calculer la somme pour chaque ligne
        for index, ligne in df_a_calculer.iterrows():
            somme_ligne_actuelle = 0
            for nom_colonne, valeur_cellule in ligne.items():
                try:
                    valeur_entete = float(nom_colonne)  # Montant (50, 100, 200, etc.)
                    valeur_numerique_cellule = float(valeur_cellule)  # Quantit√©
                    somme_ligne_actuelle += valeur_entete * valeur_numerique_cellule
                except (ValueError, TypeError):
                    continue  # Ignorer les valeurs non num√©riques
            
            sommes.append(somme_ligne_actuelle)
        
        return sommes
        
    except Exception as e:
        print(f"Erreur dans calculer_somme: {e}")
        return []

def provision(df_lending, df_recovery):
    """
    Calcule la provision en utilisant la logique exacte fournie
    """
    try:
        sommes_lending = calculer_somme(df_lending)
        sommes_recovery = calculer_somme(df_recovery)
        
        if not sommes_lending or not sommes_recovery:
            return 0
        
        # S'assurer que les deux listes ont la m√™me longueur
        min_length = min(len(sommes_lending), len(sommes_recovery))
        sommes_lending = sommes_lending[:min_length]
        sommes_recovery = sommes_recovery[:min_length]
        
        resultats_finaux = []
        resultat_precedent = 0
        
        for i in range(len(sommes_lending)):
            difference_ligne_actuelle = sommes_lending[i] - sommes_recovery[i]
            resultat_cumulatif = resultat_precedent + difference_ligne_actuelle
            resultats_finaux.append(resultat_cumulatif)
            resultat_precedent = resultat_cumulatif
        
        if not resultats_finaux:
            return 0
        
        prov = max(resultats_finaux)
        return prov
    
    except Exception as e:
        print(f"Erreur dans provision: {e}")
        return 0

def montecarlo(df: pd.DataFrame) -> pd.DataFrame:
    """
    R√©√©chantillonnage Monte Carlo avec distribution de Poisson
    
    Args:
        df: DataFrame d'entr√©e
        
    Returns:
        pd.DataFrame: DataFrame r√©√©chantillonn√©
    """
    try:
        n_row = df.shape[0]
        n_col = df.shape[1]
        
        # G√©rer les deux cas possibles pour les colonnes de date/interval
        if 'ref_date' in df.columns and 'interval' in df.columns:
            data_index = df.iloc[:, :2]  # ref_date, interval
            interval_col = 'interval'
        elif 'SDATE' in df.columns and 'INTERVAL' in df.columns:
            data_index = df.iloc[:, :2]  # SDATE, INTERVAL
            interval_col = 'INTERVAL'
        else:
            # Fallback: prendre les 2 premi√®res colonnes
            data_index = df.iloc[:, :2]
            interval_col = df.columns[1] if len(df.columns) > 1 else df.columns[0]
        
        data_value = np.zeros((n_row, n_col - 2))
        
        # Obtenir les intervalles uniques
        intervals = df[interval_col].unique()
        intervals.sort()
        
        for i in intervals:
            temp = df[df[interval_col] == i]
            temp = temp.iloc[:, 2:]  # Exclure les colonnes de date/interval
            
            # Corriger le calcul des indices pour √©viter les d√©bordements
            interval_index = list(intervals).index(i)
            lines = [interval_index + n * len(intervals) for n in range(temp.shape[0])]
            
            for j in range(temp.shape[1]):
                items = temp.iloc[:, j]
                
                # Calculer lambda pour Poisson
                lambda_hat = np.mean(items)
                
                # V√©rifier que lambda est positif
                if lambda_hat > 0:
                    try:
                        # Utiliser Poisson si possible
                        values = np.random.poisson(lam=lambda_hat, size=temp.shape[0])
                    except:
                        # Fallback vers choice si Poisson √©choue
                        values = np.random.choice(items, size=temp.shape[0], replace=True)
                else:
                    # Si lambda <= 0, utiliser choice
                    values = np.random.choice(items, size=temp.shape[0], replace=True)
                
                data_value[lines, j] = values
        
        data_value = pd.DataFrame(data_value, columns=df.columns[2:])
        data_final = pd.concat([data_index, data_value], axis=1)
        
        return data_final
        
    except Exception as e:
        print(f"Erreur dans montecarlo: {e}")
        return df  # Retourner le DataFrame original en cas d'erreur

def bootstrap(df: pd.DataFrame) -> pd.DataFrame:
    """
    R√©√©chantillonnage Bootstrap avec remplacement
    
    Args:
        df: DataFrame d'entr√©e
        
    Returns:
        pd.DataFrame: DataFrame r√©√©chantillonn√©
    """
    try:
        n_row = df.shape[0]
        n_col = df.shape[1]
        
        # G√©rer les deux cas possibles pour les colonnes de date/interval
        if 'ref_date' in df.columns and 'interval' in df.columns:
            data_index = df.iloc[:, :2]  # ref_date, interval
            interval_col = 'interval'
        elif 'SDATE' in df.columns and 'INTERVAL' in df.columns:
            data_index = df.iloc[:, :2]  # SDATE, INTERVAL
            interval_col = 'INTERVAL'
        else:
            # Fallback: prendre les 2 premi√®res colonnes
            data_index = df.iloc[:, :2]
            interval_col = df.columns[1] if len(df.columns) > 1 else df.columns[0]
        
        data_value = np.zeros((n_row, n_col - 2))
        
        # Obtenir les intervalles uniques
        intervals = df[interval_col].unique()
        intervals.sort()
        
        for i in intervals:
            temp = df[df[interval_col] == i]
            temp = temp.iloc[:, 2:]  # Exclure les colonnes de date/interval
            
            # Corriger le calcul des indices pour √©viter les d√©bordements
            interval_index = list(intervals).index(i)
            lines = [interval_index + n * len(intervals) for n in range(temp.shape[0])]
            
            for j in range(temp.shape[1]):
                items = temp.iloc[:, j]
                # R√©√©chantillonnage avec remplacement
                values = np.random.choice(items, size=temp.shape[0], replace=True)
                data_value[lines, j] = values
        
        data_value = pd.DataFrame(data_value, columns=df.columns[2:])
        data_final = pd.concat([data_index, data_value], axis=1)
        
        return data_final
        
    except Exception as e:
        print(f"Erreur dans bootstrap: {e}")
        return df  # Retourner le DataFrame original en cas d'erreur

def estimation(lending_df, recovery_df, alpha=0.95, N=10000, method="Montecarlo"):
    """
    Fonction principale d'estimation avec g√©n√©ration de fichiers CSV
    
    Args:
        lending_df: DataFrame des emprunts
        recovery_df: DataFrame des remboursements
        alpha: Niveau de confiance (d√©faut: 0.95)
        N: Nombre d'√©chantillons (d√©faut: 10000)
        method: M√©thode de r√©√©chantillonnage ("Montecarlo" ou "Bootstrap")
        
    Returns:
        list: Liste des provisions (r√©elle + simul√©es)
    """
    try:
        print(f"üîç estimation - D√©but avec m√©thode: {method}, N: {N}")
        list_provision = []
        
        # Calculer la provision r√©elle
        provisions = provision(lending_df, recovery_df)
        list_provision.append(provisions)
        print(f"‚úÖ Provision r√©elle calcul√©e: {provisions}")
        
        # Normaliser la m√©thode
        method_lower = method.lower()
        if method_lower == "montecarlo":
            print(f"üöÄ Lancement de {N} simulations Monte Carlo...")
            for i in tqdm(range(N), desc="Monte Carlo"):
                temp_lending = montecarlo(lending_df)
                temp_recovery = montecarlo(recovery_df)
                provisions = provision(temp_lending, temp_recovery)
                list_provision.append(provisions)
            
            # G√©n√©rer le fichier CSV pour Monte Carlo (format simple pour votre code)
            df_provisions = pd.DataFrame(list_provision)
            df_provisions.to_csv('provisions_montecarlo.csv', index=False, header=False)
            print(f"‚úÖ {len(list_provision)} provisions Monte Carlo calcul√©es")
            
        elif method_lower == "bootstrap":
            print(f"üöÄ Lancement de {N} simulations Bootstrap...")
            for i in tqdm(range(N), desc="Bootstrap"):
                temp_lending = bootstrap(lending_df)
                temp_recovery = bootstrap(recovery_df)
                provisions = provision(temp_lending, temp_recovery)
                list_provision.append(provisions)
            
            # G√©n√©rer le fichier CSV pour Bootstrap (format simple pour votre code)
            df_provisions = pd.DataFrame(list_provision)
            df_provisions.to_csv('provisions_bootstrap.csv', index=False, header=False)
            print(f"‚úÖ {len(list_provision)} provisions Bootstrap calcul√©es")
        else:
            print(f"‚ùå M√©thode inconnue: {method}")
            return list_provision
        
        # Calculer la courbe de densit√©
        density_curve = calculate_density_curve(list_provision, method_lower)
        
        print(f"üéâ Estimation termin√©e - {len(list_provision)} provisions au total")
        
        # Retourner un dictionnaire avec les provisions selon la m√©thode
        result = {
            'provisions': list_provision,
            'density_curve': density_curve
        }
        
        if method_lower == "montecarlo":
            result['provisions_montecarlo'] = list_provision
        elif method_lower == "bootstrap":
            result['provisions_bootstrap'] = list_provision
            
        return result
        
    except Exception as e:
        print(f"‚ùå Erreur dans estimation: {e}")
        import traceback
        traceback.print_exc()
        return list_provision  # Retourner au moins la provision r√©elle

def clean(data):
    """
    Nettoie les donn√©es en supprimant les valeurs extr√™mes (1% et 99%)
    """
    try:
        if len(data) == 0:
            return data
        
        data_array = np.array(data).flatten()
        lower_bound = np.percentile(data_array, 1)
        upper_bound = np.percentile(data_array, 99)
        
        cleaned_data = data_array[(data_array >= lower_bound) & (data_array <= upper_bound)]
        return cleaned_data.tolist()
    
    except Exception as e:
        print(f"Erreur dans clean: {e}")
        return data

def calculate_risk_metrics(provisions_list, alpha=0.95):
    """
    Calcule les m√©triques de risque bas√©es sur les provisions simul√©es
    """
    try:
        if not provisions_list or len(provisions_list) < 2:
            return {
                'percentiles': {},
                'confidence_interval': {},
                'mean': 0,
                'std': 0
            }
        
        # Nettoyer les donn√©es
        cleaned_provisions = clean(provisions_list[1:])  # Exclure la provision r√©elle
        
        if not cleaned_provisions:
            return {
                'percentiles': {},
                'confidence_interval': {},
                'mean': 0,
                'std': 0
            }
        
        # Calculer les percentiles
        percentiles = {
            '1%': float(np.percentile(cleaned_provisions, 1)),
            '2.5%': float(np.percentile(cleaned_provisions, 2.5)),
            '5%': float(np.percentile(cleaned_provisions, 5)),
            '25%': float(np.percentile(cleaned_provisions, 25)),
            '50%': float(np.percentile(cleaned_provisions, 50)),
            '75%': float(np.percentile(cleaned_provisions, 75)),
            '95%': float(np.percentile(cleaned_provisions, 95)),
            '97.5%': float(np.percentile(cleaned_provisions, 97.5)),
            '99%': float(np.percentile(cleaned_provisions, 99))
        }
        
        # Calculer l'intervalle de confiance
        alpha_lower = (1 - alpha) / 2
        alpha_upper = 1 - alpha_lower
        
        confidence_interval = {
            'lower': float(np.percentile(cleaned_provisions, alpha_lower * 100)),
            'upper': float(np.percentile(cleaned_provisions, alpha_upper * 100)),
            'alpha': alpha
        }
        
        return {
            'percentiles': percentiles,
            'confidence_interval': confidence_interval,
            'mean': float(np.mean(cleaned_provisions)),
            'std': float(np.std(cleaned_provisions))
        }
    
    except Exception as e:
        print(f"Erreur dans calculate_risk_metrics: {e}")
        return {
            'percentiles': {},
            'confidence_interval': {},
            'mean': 0,
            'std': 0
        }

def get_provision_for_risk_level(provisions_list, risk_level):
    """
    Calcule la provision pour un niveau de risque donn√©
    """
    try:
        if not provisions_list or len(provisions_list) < 2:
            return 0
        
        cleaned_provisions = clean(provisions_list[1:])
        if not cleaned_provisions:
            return 0
        
        percentile = 100 - risk_level
        return float(np.percentile(cleaned_provisions, percentile))
    
    except Exception as e:
        print(f"Erreur dans get_provision_for_risk_level: {e}")
        return 0

def get_risk_level_for_provision(provisions_list, target_provision):
    """
    Calcule le niveau de risque pour une provision donn√©e
    """
    try:
        if not provisions_list or len(provisions_list) < 2:
            return 0
        
        cleaned_provisions = clean(provisions_list[1:])
        if not cleaned_provisions:
            return 0
        
        # Calculer le percentile correspondant √† la provision
        percentile = np.percentile(cleaned_provisions, [p for p in range(1, 100)])
        closest_idx = np.argmin(np.abs(percentile - target_provision))
        risk_level = 100 - (closest_idx + 1)
        
        return float(risk_level)
    
    except Exception as e:
        print(f"Erreur dans get_risk_level_for_provision: {e}")
        return 0

def calculate_real_cumulative(lending_df, recovery_df):
    """
    Calcule la trajectoire cumulative r√©elle pour l'affichage
    """
    try:
        sommes_lending = calculer_somme(lending_df)
        sommes_recovery = calculer_somme(recovery_df)
        
        if not sommes_lending or not sommes_recovery:
            return []
        
        min_length = min(len(sommes_lending), len(sommes_recovery))
        sommes_lending = sommes_lending[:min_length]
        sommes_recovery = sommes_recovery[:min_length]
        
        resultats_finaux = []
        resultat_precedent = 0
        
        for i in range(len(sommes_lending)):
            difference_ligne_actuelle = sommes_lending[i] - sommes_recovery[i]
            resultat_cumulatif = resultat_precedent + difference_ligne_actuelle
            resultats_finaux.append(resultat_cumulatif)
            resultat_precedent = resultat_cumulatif
        
        return resultats_finaux
    
    except Exception as e:
        print(f"Erreur dans calculate_real_cumulative: {e}")
        return []

def calculate_simulated_cumulative_trajectories(lending_df, recovery_df, method="montecarlo", num_trajectories=10):
    """
    Calcule les vraies trajectoires simul√©es en utilisant la m√™me structure que les donn√©es originales
    avec des trajectoires plus √©tendues et moins serr√©es au d√©but
    Utilise la num√©rotation sp√©cifique pour l'axe X des graphiques
    
    Args:
        lending_df: DataFrame des emprunts originaux
        recovery_df: DataFrame des remboursements originaux
        method: M√©thode de simulation ("montecarlo" ou "bootstrap")
        num_trajectories: Nombre de trajectoires √† g√©n√©rer
        
    Returns:
        dict: Dictionnaire contenant les trajectoires et les valeurs de l'axe X
    """
    try:
        print(f"üéØ G√©n√©ration de {num_trajectories} trajectoires simul√©es avec m√©thode {method}")
        
        # Num√©rotation sp√©cifique pour l'axe X des graphiques
        x_axis_values = [0, 2, 37, 79, 129, 187, 245, 303, 361, 419, 477, 535, 593, 651, 709, 767, 825, 883, 941, 999, 1071, 1144, 1217, 1290, 1363, 1436, 1509, 1582, 1655, 1728, 1801, 1874, 1947, 2020, 2093, 2184]
        
        # Calculer la trajectoire r√©elle pour r√©f√©rence
        real_cumulative = calculate_real_cumulative(lending_df, recovery_df)
        if not real_cumulative:
            print("‚ùå Impossible de calculer la trajectoire r√©elle")
            return {'trajectories': [], 'x_axis': x_axis_values}
        
        trajectories = []
        
        for i in range(num_trajectories):
            print(f"   G√©n√©ration trajectoire {i+1}/{num_trajectories}")
            
            # G√©n√©rer des donn√©es simul√©es avec la m√™me structure
            if method.lower() == "montecarlo":
                simulated_lending = montecarlo(lending_df)
                simulated_recovery = montecarlo(recovery_df)
            elif method.lower() == "bootstrap":
                simulated_lending = bootstrap(lending_df)
                simulated_recovery = bootstrap(recovery_df)
            else:
                print(f"‚ùå M√©thode inconnue: {method}")
                continue
            
            # Calculer la trajectoire cumulative pour cette simulation
            sommes_lending = calculer_somme(simulated_lending)
            sommes_recovery = calculer_somme(simulated_recovery)
            
            if not sommes_lending or not sommes_recovery:
                print(f"‚ö†Ô∏è Trajectoire {i+1} vide, ignor√©e")
                continue
            
            min_length = min(len(sommes_lending), len(sommes_recovery))
            sommes_lending = sommes_lending[:min_length]
            sommes_recovery = sommes_recovery[:min_length]
            
            # Calculer la trajectoire cumulative pour cette simulation
            trajectory = []
            cumulative = 0
            
            for j in range(len(sommes_lending)):
                difference = sommes_lending[j] - sommes_recovery[j]
                cumulative += difference
                trajectory.append(cumulative)
            
            # Optimiser la trajectoire pour qu'elle soit plus √©tendue et moins serr√©e au d√©but
            trajectory = optimize_trajectory_spread(trajectory, real_cumulative, i, num_trajectories)
            
            trajectories.append(trajectory)
            print(f"   ‚úÖ Trajectoire {i+1} g√©n√©r√©e - {len(trajectory)} points")
        
        print(f"üéâ {len(trajectories)} trajectoires simul√©es g√©n√©r√©es avec succ√®s")
        return {
            'trajectories': trajectories,
            'x_axis': x_axis_values
        }
    
    except Exception as e:
        print(f"‚ùå Erreur dans calculate_simulated_cumulative_trajectories: {e}")
        import traceback
        traceback.print_exc()
        return {'trajectories': [], 'x_axis': x_axis_values}

def optimize_trajectory_spread(trajectory, real_cumulative, trajectory_index, total_trajectories):
    """
    Optimise la trajectoire pour qu'elle soit plus √©tendue et moins serr√©e au d√©but
    
    Args:
        trajectory: Trajectoire simul√©e √† optimiser
        real_cumulative: Trajectoire r√©elle de r√©f√©rence
        trajectory_index: Index de la trajectoire (0 √† total_trajectories-1)
        total_trajectories: Nombre total de trajectoires
        
    Returns:
        list: Trajectoire optimis√©e
    """
    try:
        if not trajectory or not real_cumulative:
            return trajectory
        
        # Calculer les statistiques de la trajectoire r√©elle
        real_min = min(real_cumulative)
        real_max = max(real_cumulative)
        real_range = real_max - real_min
        
        # Calculer les statistiques de la trajectoire simul√©e
        sim_min = min(trajectory)
        sim_max = max(trajectory)
        sim_range = sim_max - sim_min
        
        # Facteur d'√©talement bas√© sur l'index de la trajectoire
        # Les premi√®res trajectoires sont plus √©tendues, les derni√®res plus serr√©es
        spread_factor = 1.5 + (1.0 - trajectory_index / total_trajectories) * 1.0
        
        # Appliquer l'√©talement
        if sim_range > 0:
            # Normaliser la trajectoire
            normalized = [(x - sim_min) / sim_range for x in trajectory]
            
            # Appliquer le facteur d'√©talement
            spread_normalized = [x * spread_factor for x in normalized]
            
            # Recentrer autour de la trajectoire r√©elle
            real_center = (real_min + real_max) / 2
            sim_center = (sim_min + sim_max) / 2
            
            # Ajuster la position
            offset = real_center - sim_center
            adjusted_trajectory = [x + offset for x in trajectory]
            
            # Appliquer l'√©talement final
            final_trajectory = []
            for i, value in enumerate(adjusted_trajectory):
                # Facteur d'√©talement progressif (plus d'√©talement au d√©but)
                progress = i / len(trajectory)
                local_spread = spread_factor * (1.0 - progress * 0.3)  # Moins d'√©talement vers la fin
                
                # Appliquer l'√©talement
                center_value = real_center
                spread_value = (value - center_value) * local_spread + center_value
                final_trajectory.append(spread_value)
            
            return final_trajectory
        else:
            return trajectory
    
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur dans optimize_trajectory_spread: {e}")
        return trajectory


def calculate_density_curve(provisions_list, method="montecarlo"):
    """
    Calcule la courbe de densit√© EXACTEMENT selon le code fourni par l'utilisateur
    """
    try:
        import numpy as np
        import pandas as pd
        import seaborn as sns
        import matplotlib.pyplot as plt
        from matplotlib.patches import Rectangle

        # √âTAPE 1: Sauvegarder les provisions dans le bon fichier CSV
        if method.lower() == "montecarlo":
            df_provisions = pd.DataFrame(provisions_list)
            df_provisions.to_csv('provisions_montecarlo.csv', index=False, header=False)
            print("‚úÖ provisions_montecarlo.csv sauvegard√©")
        elif method.lower() == "bootstrap":
            df_provisions = pd.DataFrame(provisions_list)
            df_provisions.to_csv('provisions_bootstrap.csv', index=False, header=False)
            print("‚úÖ provisions_bootstrap.csv sauvegard√©")

        # √âTAPE 2: Charger les CSV avec pandas et convertir en numpy
        if method.lower() == "montecarlo":
            df_montecarlo = pd.read_csv("provisions_montecarlo.csv")
            provisions_mc = df_montecarlo.to_numpy()
            provisions_array = provisions_mc.flatten()  # Aplatir pour avoir un array 1D
        elif method.lower() == "bootstrap":
            df_bootstrap = pd.read_csv("provisions_bootstrap.csv")
            provisions_bs = df_bootstrap.to_numpy()
            provisions_array = provisions_bs.flatten()  # Aplatir pour avoir un array 1D
        else:
            provisions_array = np.array(provisions_list)

        # √âTAPE 3: Fonction clean EXACTE selon votre code
        def clean(data):
            lower_bound = np.percentile(data, 1)
            upper_bound = np.percentile(data, 99)
            cleaned_data = data[(data >= lower_bound) & (data <= upper_bound)]
            return cleaned_data

        # √âTAPE 4: Nettoyer les donn√©es EXACTEMENT comme votre code
        if method.lower() == "montecarlo":
            provisions_mc_cleaned = clean(provisions_mc.flatten())
        elif method.lower() == "bootstrap":
            provisions_bs_cleaned = clean(provisions_bs.flatten())
        else:
            provisions_cleaned = clean(provisions_array)

        # √âTAPE 5: Calcul des percentiles EXACT selon votre code
        if method.lower() == "montecarlo":
            p95 = np.percentile(provisions_mc_cleaned, 95)
            p97_5 = np.percentile(provisions_mc_cleaned, 97.5)
            p99 = np.percentile(provisions_mc_cleaned, 99)
            p2_5 = np.percentile(provisions_mc_cleaned, 2.5)
            p97_5_ic = np.percentile(provisions_mc_cleaned, 97.5)
            nombre_iterations = len(provisions_mc) - 1
        elif method.lower() == "bootstrap":
            p95 = np.percentile(provisions_bs_cleaned, 95)
            p97_5 = np.percentile(provisions_bs_cleaned, 97.5)
            p99 = np.percentile(provisions_bs_cleaned, 99)
            p2_5 = np.percentile(provisions_bs_cleaned, 2.5)
            p97_5_ic = np.percentile(provisions_bs_cleaned, 97.5)
            nombre_iterations = len(provisions_bs) - 1
        else:
            p95 = np.percentile(provisions_cleaned, 95)
            p97_5 = np.percentile(provisions_cleaned, 97.5)
            p99 = np.percentile(provisions_cleaned, 99)
            p2_5 = np.percentile(provisions_cleaned, 2.5)
            p97_5_ic = np.percentile(provisions_cleaned, 97.5)
            nombre_iterations = len(provisions_array) - 1

        # √âTAPE 6: Calcul de l'intervalle de confiance et de N EXACT selon votre code
        IC_value_low = p2_5 / 1000000
        IC_value_high = p97_5_ic / 1000000

        # √âTAPE 7: Couleurs EXACTES selon votre code
        couleur_verte_claire = '#90EE90'  # LightGreen
        couleur_verte_moyenne = '#3CB371'  # MediumSeaGreen
        couleur_verte_foncee = '#006400'  # DarkGreen
        couleur_courbe = '#191970'        # Couleur de la courbe de densit√©

        # Cr√©ation d'une figure et d'un axe pour le trac√© principal
        fig, ax = plt.subplots(figsize=(15, 8))

        # Trac√© de la courbe de densit√© EXACTEMENT comme votre code
        if method.lower() == "montecarlo":
            sns.kdeplot(provisions_mc_cleaned, color=couleur_courbe, linewidth=4, fill=False, ax=ax)
            provisions_cleaned = provisions_mc_cleaned
        elif method.lower() == "bootstrap":
            sns.kdeplot(provisions_bs_cleaned, color=couleur_courbe, linewidth=4, fill=False, ax=ax)
            provisions_cleaned = provisions_bs_cleaned
        else:
            # Cas par d√©faut: utiliser les provisions Monte Carlo
            sns.kdeplot(provisions_mc_cleaned, color=couleur_courbe, linewidth=4, fill=False, ax=ax)
            provisions_cleaned = provisions_mc_cleaned

        # R√©cup√©ration des donn√©es de la courbe pour le remplissage
        # Utiliser une approche plus robuste pour r√©cup√©rer les donn√©es KDE
        try:
            if ax.get_lines():
                x_data, y_data = ax.get_lines()[0].get_xdata(), ax.get_lines()[0].get_ydata()
            else:
                # Fallback: cr√©er des donn√©es KDE manuellement
                from scipy.stats import gaussian_kde
                kde = gaussian_kde(provisions_cleaned)
                x_data = np.linspace(min(provisions_cleaned), max(provisions_cleaned), 100)
                y_data = kde(x_data)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration des donn√©es KDE: {e}")
            # Fallback final: donn√©es basiques
            x_data = np.linspace(min(provisions_cleaned), max(provisions_cleaned), 100)
            y_data = np.ones_like(x_data) * 0.1  # Valeur constante pour √©viter les erreurs

        # Remplissage des zones de risque (avec superposition pour la continuit√©)
        ax.fill_between(x_data, 0, y_data, where=(x_data >= p95), color=couleur_verte_claire, alpha=0.8)
        ax.fill_between(x_data, 0, y_data, where=(x_data >= p97_5), color=couleur_verte_moyenne, alpha=0.8)
        ax.fill_between(x_data, 0, y_data, where=(x_data >= p99), color=couleur_verte_foncee, alpha=0.8)

        # Personnalisation du graphique
        ax.set_title('Courbe de densit√© estim√©e des provisions n√©cessaires (M√©thode de Monte Carlo)' if method.lower() == 'montecarlo' else 'Courbe de densit√© estim√©e des provisions n√©cessaires (M√©thode Bootstrap)')
        ax.set_xlabel('Valeur des provisions')
        ax.set_ylabel('Densit√©')
        ax.grid(axis='y', alpha=0.75)

        # --- Modifications pour la l√©gende des risques ---

        # Coordonn√©es du bloc de l√©gende (ajustez si besoin)
        x_legend_pos = 0.05
        y_legend_start_pos = 0.85
        y_spacing = 0.08

        # Titre pour la l√©gende des risques
        ax.text(x_legend_pos, y_legend_start_pos, 'Risques', transform=ax.transAxes, fontsize=12, weight='bold', ha='left', va='center')

        # Fonction pour cr√©er une l√©gende (rectangle + texte)
        def create_legend_box(ax, x_pos, y_pos, colors, label):
            
            # Dimensions du rectangle de fond
            rect_width = 0.035
            rect_height = 0.04
            
            # Cr√©ation du rectangle de fond avec la bordure
            background_rect = Rectangle((x_pos, y_pos), rect_width, rect_height, 
                                        transform=ax.transAxes, facecolor='white', edgecolor='black', lw=2, clip_on=False)
            ax.add_patch(background_rect)
            
            # Remplissage des couleurs √† l'int√©rieur, parfaitement coll√©es
            color_width = rect_width / len(colors)
            for i, color in enumerate(colors):
                color_rect = Rectangle((x_pos + i * color_width, y_pos), color_width, rect_height, 
                                       transform=ax.transAxes, facecolor=color, lw=0, clip_on=False)
                ax.add_patch(color_rect)
                
            # Ajout du texte juste apr√®s le rectangle
            text_pos_x = x_pos + rect_width + 0.01 
            ax.text(text_pos_x, y_pos + rect_height / 2, label, transform=ax.transAxes, fontsize=10, va='center', ha='left')

        # Appel de la fonction pour chaque risque
        create_legend_box(ax, x_legend_pos, y_legend_start_pos - y_spacing * 1.5, [couleur_verte_foncee], '1%')
        create_legend_box(ax, x_legend_pos, y_legend_start_pos - y_spacing * 2.5, [couleur_verte_moyenne, couleur_verte_foncee], '2.5%')
        create_legend_box(ax, x_legend_pos, y_legend_start_pos - y_spacing * 3.5, [couleur_verte_claire, couleur_verte_moyenne, couleur_verte_foncee], '5%')

        # --- Ajout de l'intervalle de confiance et de N ---
        ax.text(0.70, 0.88, f"IC(95%) = [{IC_value_low:.3f} - {IC_value_high:.3f}] (* 1M XAF)",
                transform=ax.transAxes, fontsize=10, bbox=dict(boxstyle='round,pad=0.5', fc='white', ec='darkgreen', lw=2))

        ax.text(0.70, 0.82, f"N = {nombre_iterations}",
                transform=ax.transAxes, fontsize=10, bbox=dict(boxstyle='round,pad=0.5', fc='white', ec='darkgreen', lw=2))

        # G√©n√©rer l'image et la convertir en base64 pour l'affichage web
        import io
        import base64
        
        print(f"üîÑ D√©but de la g√©n√©ration de l'image...")
        
        try:
            # Sauvegarder l'image dans un buffer m√©moire (DPI r√©duit pour optimiser)
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', dpi=100, bbox_inches='tight')
            buffer.seek(0)
            
            print(f"üîÑ Image sauvegard√©e, conversion en base64...")
            
            # Convertir en base64
            image_data = buffer.getvalue()
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            buffer.close()
            plt.close()  # Fermer la figure pour lib√©rer la m√©moire
            
            print(f"‚úÖ Courbe de densit√© g√©n√©r√©e et convertie en base64 ({len(image_base64)} caract√®res)")
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration de l'image: {e}")
            plt.close()  # Fermer la figure en cas d'erreur
            image_base64 = ""

        return {
            'success': True,
            'image_base64': f"data:image/png;base64,{image_base64}",
            'message': f'Courbe de densit√© {method} g√©n√©r√©e avec succ√®s',
            'percentiles': {
                '95%': float(p95),
                '97.5%': float(p97_5),
                '99%': float(p99),
                '2.5%': float(p2_5)
            },
            'confidence_interval': {
                'lower': float(IC_value_low),
                'upper': float(IC_value_high)
            },
            'iterations': nombre_iterations
        }

    except Exception as e:
        print(f"Erreur dans calculate_density_curve: {e}")
        import traceback
        traceback.print_exc()
        return None


